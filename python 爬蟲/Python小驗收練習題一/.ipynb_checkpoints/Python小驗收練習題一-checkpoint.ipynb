{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "# from bs4 import BeautifulSoup as bs\n",
    "# from lxml import html\n",
    "# from lxml import cssselect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = requests.get('https://technews.tw/')\n",
    "# soup = bs(res.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(soup))\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_titles = soup.select('#album_test1 > div > ul > li ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(row_titles))\n",
    "# row_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results=[]\n",
    "# for i,j in enumerate(row_titles):\n",
    "#     try:\n",
    "#         results=[]\n",
    "#         for i,j in enumerate(row_titles):\n",
    "#             result={} \n",
    "#             spotlists=[]\n",
    "#             i+=1\n",
    "#             result['category'] = j.find('div','cat01').text\n",
    "#             result['sum_title'] = j.find('h3').text\n",
    "#             result['sum_title_url'] ='https:'+j.find('a').get('href')\n",
    "#             raw_titles = soup.select('#album_test1 > div > ul > li:nth-child({}) > div.itemelse > ul > li > a'.format(i))\n",
    "#             for k in raw_titles:\n",
    "#                 spotlist={}\n",
    "#                 spotlist['title'] =k.text\n",
    "#                 spotlist['url'] ='https:'+k.get('href')\n",
    "#                 spotlists.append(spotlist)\n",
    "#             result['spotlist']=spotlists\n",
    "#             results.append(result)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(i)\n",
    "#         continue\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'Exam1_1.json'\n",
    "# with open(file_name,'w', encoding = 'utf8' ) as file_object:\n",
    "#         json.dump(results,file_object,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'Exam1_1.json'\n",
    "# with open(file_name,'r', encoding = 'utf8' ) as file_object:\n",
    "#     jf = json.loads(file_object.read())\n",
    "# jf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j in enumerate(jf):\n",
    "    \n",
    "#     sum_all=''\n",
    "#     url=jf[0]['sum_title_url']\n",
    "#     res = requests.get(url)\n",
    "#     soup = bs(res.text,'lxml')\n",
    "#     row_titles = soup.select('div > div.entry-content > div.indent > p')\n",
    "#     for p in row_titles:\n",
    "#         sum_all=sum_all+p.text\n",
    "\n",
    "#     file_name_sum = ('sum_{}_{}.txt'.format(jf[i]['category'],jf[i]['sum_title'][0:4]))\n",
    "#     with open(file_name_sum,'w', encoding = 'utf8' ) as file_object:\n",
    "#         json.dump(sum_all,file_object,ensure_ascii=False)\n",
    "        \n",
    "#     for k in range(3):\n",
    "#         url=jf[i]['spotlist'][k]['url']\n",
    "#         spot_all=''\n",
    "#         res = requests.get(url)\n",
    "#         soup = bs(res.text,'lxml')\n",
    "#         row_titles = soup.select('div > div.entry-content > div.indent > p')\n",
    "#         for p in row_titles:\n",
    "#             spot_all=spot_all+p.text\n",
    "\n",
    "#         file_name_spot = ('spot_{}_{}.txt'.format(jf[i]['category'],jf[i]['spotlist'][k]['title'][0:4]))\n",
    "#         with open(file_name_spot,'w', encoding = 'utf8' ) as file_object:\n",
    "#             json.dump(spot_all,file_object,ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
